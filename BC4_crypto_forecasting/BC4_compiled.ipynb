{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856b8846",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7eebe9882cb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m#LSTM Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go \n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from colorama import Fore\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.offline as py\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#importing packages for the prediction of time-series data\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from scipy import stats\n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import math\n",
    "import ta\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from itertools import cycle\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from functools import reduce\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "#LSTM Model\n",
    "from keras.layers import Dense,LSTM,Dropout\n",
    "from keras.models import Sequential,Model\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003335ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mdurh\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "close=pd.read_csv('data/close.csv')\n",
    "adj_close=pd.read_csv('data/adj_close.csv')\n",
    "open=pd.read_csv('data/open.csv')\n",
    "high=pd.read_csv('data/open.csv')\n",
    "low=pd.read_csv('data/low.csv')\n",
    "volume=pd.read_csv('data/volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "close=pd.read_csv('data_updated/close.csv')\n",
    "adj_close=pd.read_csv('data_updated/adj_close.csv')\n",
    "open=pd.read_csv('data_updated/open.csv')\n",
    "high=pd.read_csv('data_updated/open.csv')\n",
    "low=pd.read_csv('data_updated/low.csv')\n",
    "volume=pd.read_csv('data_updated/volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dataframes = [close, adj_close, open, high, low, volume]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'], how='outer'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f500f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency(curr): \n",
    "    df=df_merged[['Date',curr+'_x', curr+'_y']]\n",
    "    df.columns = ['Date','Close', 'Adj_Close','Open','High', 'Low', 'Volume']\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    df.name=curr\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f26b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADA=currency('ADA-USD')\n",
    "ATOM=currency('ATOM-USD')\n",
    "AVAX=currency('AVAX-USD')\n",
    "AXS=currency('AXS-USD')\n",
    "BTC=currency('BTC-USD')\n",
    "ETH=currency('ETH-USD')\n",
    "LINK=currency('LINK-USD')\n",
    "LUNA1=currency('LUNA1-USD')\n",
    "MATIC=currency('MATIC-USD')\n",
    "SOL=currency('SOL-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aedfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler().fit(close[['ADA-USD','ATOM-USD','AVAX-USD','AXS-USD','BTC-USD','ETH-USD','LINK-USD','LUNA1-USD',\n",
    "                                  'MATIC-USD','SOL-USD']])\n",
    "closescaled = scaler.transform(close[['ADA-USD','ATOM-USD','AVAX-USD','AXS-USD','BTC-USD','ETH-USD','LINK-USD','LUNA1-USD',\n",
    "                                  'MATIC-USD','SOL-USD']])\n",
    "close[['ADA-USD','ATOM-USD','AVAX-USD','AXS-USD','BTC-USD','ETH-USD','LINK-USD','LUNA1-USD',\n",
    "                                  'MATIC-USD','SOL-USD']] = closescaled\n",
    "close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee577e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['ADA-USD'],\n",
    "                  name='ADA'\n",
    "                  )\n",
    "\n",
    "trace2 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['AVAX-USD'],\n",
    "                  name='AVAX'\n",
    "                  )\n",
    "\n",
    "trace3 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['ATOM-USD'],\n",
    "                  name='ATOM'\n",
    "                  )\n",
    "\n",
    "trace4 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['AXS-USD'],\n",
    "                  name='AXS'\n",
    "                  )\n",
    "\n",
    "\n",
    "trace5 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['ETH-USD'],\n",
    "                  name='ETH'\n",
    "                  )\n",
    "trace6 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['LINK-USD'],\n",
    "                  name='LINK'\n",
    "                  )\n",
    "trace7 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['LUNA1-USD'],\n",
    "                  name='LUNA1'\n",
    "                  )\n",
    "\n",
    "trace8 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['MATIC-USD'],\n",
    "                  name='MATIC'\n",
    "                  )\n",
    "trace9 = dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['SOL-USD'],\n",
    "                  name='SOL'\n",
    "                  )\n",
    "trace10= dict(type='scatter',\n",
    "                  x=close['Date'],\n",
    "                  y=close['BTC-USD'],\n",
    "                  name='BTC'\n",
    "                  )\n",
    "\n",
    "data = [trace1, trace2,trace3, trace4,  trace5, trace6, trace7, trace8, trace9, trace10 ]\n",
    "\n",
    "layout = dict(title=dict(text='Close currency price during 2017 and 2022'),\n",
    "                  xaxis=dict(title='Date'),\n",
    "                  yaxis=dict(title='Close currency price')\n",
    "                  )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3838613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs(df): \n",
    "    trace1 = dict(type='scatter',\n",
    "                  x=df['Date'],\n",
    "                  y=df['Close'],\n",
    "                  name='Close'\n",
    "                  )\n",
    "\n",
    "    trace2 = dict(type='scatter',\n",
    "                  x=df['Date'],\n",
    "                  y=df['Open'],\n",
    "                  name='Open'\n",
    "                  )\n",
    "\n",
    "    trace3 = dict(type='scatter',\n",
    "                  x=df['Date'],\n",
    "                  y=df['High'],\n",
    "                  name='High'\n",
    "                  )\n",
    "\n",
    "    trace4 = dict(type='scatter',\n",
    "                  x=df['Date'],\n",
    "                  y=df['Low'],\n",
    "                  name='Low'\n",
    "                  )\n",
    "\n",
    "    data = [trace1, trace2,trace3, trace4]\n",
    "\n",
    "    layout = dict(title=dict(text=df.name +' Price During 2017 and 2022'),\n",
    "                      xaxis=dict(title='Date'),\n",
    "                      yaxis=dict(title='Currency Price')\n",
    "                      )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    return fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84412b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#currencies=[ADA, ATOM, AVAX, AXS, BTC, ETH, LINK, LUNA1, MATIC,SOL]\n",
    "#for i in currencies: \n",
    "#    graphs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs(ADA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336cfd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs(BTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0327a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volume\n",
    "\n",
    "#In simple words, Volume is the amount of a token traded in a specific time interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66689a",
   "metadata": {},
   "source": [
    "### Candlestick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f540bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candlestick(df): \n",
    "    data = [go.Candlestick(x=df.Date,\n",
    "                           open=df.Open,\n",
    "                           high=df.High,\n",
    "                           low=df.Low,\n",
    "                           close=df.Close)]\n",
    "    layout = go.Layout(title=df.name+' Candlestick')\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#currencies=[ADA, ATOM, AVAX, AXS, BTC, ETH, LINK, LUNA1, MATIC,SOL]\n",
    "#for i in currencies: \n",
    "#    candlestick(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae75213",
   "metadata": {},
   "outputs": [],
   "source": [
    "candlestick(BTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42cab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "candlestick(ETH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0030d372",
   "metadata": {},
   "source": [
    "## BTC ARIMA Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(x):\n",
    "\n",
    "\n",
    "    #Determing rolling statistics\n",
    "    rolmean = x.rolling(window=22,center=False).mean()\n",
    "\n",
    "    rolstd = x.rolling(window=12,center=False).std()\n",
    "    \n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(x, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey Fuller test    \n",
    "    result=adfuller(x)\n",
    "    print('ADF Stastistic: %f'%result[0])\n",
    "    print('p-value: %f'%result[1])\n",
    "    pvalue=result[1]\n",
    "    for key,value in result[4].items():\n",
    "        if result[0]>value:\n",
    "            print(\"The graph is non stationery\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"The graph is stationery\")\n",
    "            break;\n",
    "    print('Critical values:')\n",
    "    for key,value in result[4].items():\n",
    "        print('\\t%s: %.3f ' % (key, value))\n",
    "        \n",
    "ts = BTC['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0378b785",
   "metadata": {},
   "source": [
    "Since the p value is greater than 0.05 the time series is non stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "plt.plot(ts_log,color=\"green\")\n",
    "plt.show()\n",
    "\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()\n",
    "plt.plot(ts_log_diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbf733",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f95e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(ts_log, order=(2,1,0))  \n",
    "results_ARIMA = model.fit(disp=-1)  \n",
    "plt.plot(ts_log_diff)\n",
    "plt.plot(results_ARIMA.fittedvalues, color='red')\n",
    "plt.title('RSS: %.7f'% sum((results_ARIMA.fittedvalues-ts_log_diff)**2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21230f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a74030",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d775ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(0, 1, 0))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "\n",
    "    output = model_fit.forecast()\n",
    "\n",
    "    pred_value = output[0]\n",
    "\n",
    "\n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "\n",
    "    pred_value = np.exp(pred_value)\n",
    "\n",
    "    original_value = np.exp(original_value)\n",
    "\n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "\n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "\n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a19a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_SCORES=[]\n",
    "RMSE_BTC=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_BTC)\n",
    "RMSE_BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aaf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame()\n",
    "testdf['y_test'] = originals\n",
    "testdf['predict'] = predictions\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "BTC['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf01e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df): \n",
    "    trace1 = dict(type='scatter',\n",
    "                      x=df['Date'],\n",
    "                      y=df['Close'],\n",
    "                      name='Actual Values'\n",
    "                      )\n",
    "\n",
    "    trace2 = dict(type='scatter',\n",
    "                      x=df['Date'],\n",
    "                      y=df['Prediction'],\n",
    "                      name='Predictions'\n",
    "                      )\n",
    "\n",
    "\n",
    "    data = [trace1, trace2 ]\n",
    "\n",
    "    layout = dict(title=dict(text='Predictions VS Actual for ' + df.name),\n",
    "                      xaxis=dict(title='Date'),\n",
    "                      yaxis=dict(title='Close currency price')\n",
    "                      )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97813a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(BTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "next_days=[]\n",
    "pred = model_fit.forecast(3)\n",
    "next_BTC=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_BTC)\n",
    "next_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f9e61",
   "metadata": {},
   "source": [
    "## ETH ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ETH['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f86fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b79ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ac52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a313943",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(2, 1, 2))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "\n",
    "    output = model_fit.forecast()\n",
    "\n",
    "    pred_value = output[0]\n",
    "\n",
    "\n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "\n",
    "    pred_value = np.exp(pred_value)\n",
    "\n",
    "    original_value = np.exp(original_value)\n",
    "\n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "\n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "\n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_ETH=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_ETH)\n",
    "RMSE_ETH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff20775",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "ETH['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04406c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a7274",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(ETH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02891ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_ETH=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_ETH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cab1cb",
   "metadata": {},
   "source": [
    "## ADA ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e32bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ADA['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24475af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b272d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a537d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(1, 1, 2))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_ADA=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_ADA)\n",
    "RMSE_ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "ADA['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ADA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5be228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_ADA=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_ADA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c2151",
   "metadata": {},
   "source": [
    "## AVAX ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = AVAX['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ac53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e83151",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(1, 1, 2))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_AVAX=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_AVAX)\n",
    "RMSE_AVAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a29dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "AVAX['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398258a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(AVAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7620cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_AVAX=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_AVAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491ca5a",
   "metadata": {},
   "source": [
    "## AXS ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceecb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = AXS['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7cabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff44aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1140c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65018a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e089f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4711b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(1, 1, 1))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_AXS=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_AXS)\n",
    "RMSE_AXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "AXS['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69604c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(AXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_AXS=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_AXS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f5474",
   "metadata": {},
   "source": [
    "## ATOM ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ATOM['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ba7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30121cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ae298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60687758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130ae76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(0, 1, 1))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d246dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_ATOM=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_ATOM)\n",
    "RMSE_ATOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "ATOM['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f27d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ATOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_ATOM=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_ATOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a440a",
   "metadata": {},
   "source": [
    "## LINK ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219775cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = LINK['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd610f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(2, 1, 1))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_LINK=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_LINK)\n",
    "RMSE_LINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "LINK['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(LINK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_LINK=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_LINK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5bbe4",
   "metadata": {},
   "source": [
    "## LUNA1 ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd00940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = LUNA1['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4457652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400554a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d06e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(2, 1, 2))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01face74",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_LUNA1=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_LUNA1)\n",
    "RMSE_LUNA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "LUNA1['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f790b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(LUNA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_LUNA=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_LUNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7bc54e",
   "metadata": {},
   "source": [
    "## MATIC ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d37203",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = MATIC['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1191f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a05cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c611ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753470d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(2, 1, 2))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_MATIC=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_MATIC)\n",
    "RMSE_MATIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "MATIC['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5108bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(MATIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_MATIC=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_MATIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44036c4b",
   "metadata": {},
   "source": [
    "## SOL ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = SOL['Close']      \n",
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1af0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log = np.log(ts)\n",
    "test_stationarity(ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff = ts_log - ts_log.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9aaf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_log_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "qs = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "d=1\n",
    "parameters = product(ps, qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model = SARIMAX(ts_log, order=(param[0], d, param[1])).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('bad parameter combination:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da257bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789df5d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = int(len(ts_log)-100)\n",
    "# Divide into train and test\n",
    "train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]\n",
    "history = [x for x in train_arima]\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "print('Printing Predicted vs Expected Values...')\n",
    "print('\\n')\n",
    "# We go over each value in the test set and then apply ARIMA model and calculate the predicted value. We have the expected value in the test set therefore we calculate the error between predicted and expected value \n",
    "for t in range(len(test_arima)):\n",
    "    model = ARIMA(history, order=(2, 1, 2))\n",
    "    model_fit = model.fit(disp=-1)\n",
    "    \n",
    "    output = model_fit.forecast()\n",
    "    \n",
    "    pred_value = output[0]\n",
    "    \n",
    "        \n",
    "    original_value = test_arima[t+size]\n",
    "    history.append(original_value)\n",
    "    \n",
    "    pred_value = np.exp(pred_value)\n",
    "    \n",
    "    \n",
    "    original_value = np.exp(original_value)\n",
    "    \n",
    "    # Calculating the error\n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "    error_list.append(error)\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "    \n",
    "# After iterating over whole test set the overall mean error is calculated.   \n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "plt.figure(figsize=(8, 6))\n",
    "test_day = [t\n",
    "           for t in range(len(test_arima))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plt.plot(test_day, predictions, color= 'green')\n",
    "plt.plot(test_day, originals, color = 'orange')\n",
    "plt.title('Expected Vs Predicted Views Forecasting')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_SOL=math.sqrt(mean_squared_error(originals,predictions))\n",
    "RMSE_SCORES.append(RMSE_SOL)\n",
    "RMSE_SOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8614d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions,index = test_arima.index,columns=['Prediction'])\n",
    "SOL['Prediction']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(SOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the next 2 days: \n",
    "pred = model_fit.forecast(3)\n",
    "next_SOL=list(np.exp(pred[0][1:]))\n",
    "next_days.append(next_SOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eee423",
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies=['BTC', 'ETH', 'ADA', 'AVAX', 'AXS', 'ATOM', 'LINK', 'LUNA1', 'MATIC','SOL']\n",
    "data = pd.DataFrame()\n",
    "data['Currency'] = currencies\n",
    "data['RMSE_SCORE'] = RMSE_SCORES\n",
    "data['Next_Days_Predictions']=next_days\n",
    "data= data.astype({\"Next_Days_Predictions\": str})\n",
    "data[['09/05', '10/05']]=data['Next_Days_Predictions'].str.split(',', expand=True)\n",
    "data['09/05']=data['09/05'].str[1:]\n",
    "data['10/05']=data['10/05'].str[:-1]\n",
    "data.pop(\"Next_Days_Predictions\")\n",
    "data=data.sort_values('Currency')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153951b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('arima_predictions.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92053c0e",
   "metadata": {},
   "source": [
    "## XGBoost regression for all 10 currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7d1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-14T16:04:30.932847Z",
     "iopub.status.busy": "2021-09-14T16:04:30.931960Z",
     "iopub.status.idle": "2021-09-14T16:04:30.939563Z",
     "shell.execute_reply": "2021-09-14T16:04:30.938813Z",
     "shell.execute_reply.started": "2021-09-14T16:04:30.932794Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset.iloc[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset.iloc[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "close=pd.read_csv('data_updated/close.csv')\n",
    "adj_close=pd.read_csv('data_updated/adj_close.csv')\n",
    "open=pd.read_csv('data_updated/open.csv')\n",
    "high=pd.read_csv('data_updated/open.csv')\n",
    "low=pd.read_csv('data_updated/low.csv')\n",
    "volume=pd.read_csv('data_updated/volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [close, adj_close, open, high, low, volume]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'], how='outer'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency(curr): \n",
    "    df=df_merged[['Date',curr+'_x', curr+'_y']]\n",
    "    df.columns = ['Date','Close', 'Adj_Close','Open','High', 'Low', 'Volume']\n",
    "    df = ta.utils.dropna(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f26b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=currency('ADA-USD')\n",
    "atom=currency('ATOM-USD')\n",
    "avax=currency('AVAX-USD')\n",
    "axs=currency('AXS-USD')\n",
    "btc=currency('BTC-USD')\n",
    "eth=currency('ETH-USD')\n",
    "link=currency('LINK-USD')\n",
    "luna1=currency('LUNA1-USD')\n",
    "matic=currency('MATIC-USD')\n",
    "sol=currency('SOL-USD')\n",
    "\n",
    "#Dictionary with crypto names and datasets\n",
    "crypto_names = {'ADA-USD':ada, \n",
    "               'ATOM-USD':atom,\n",
    "               'AVAX-USD':avax,\n",
    "               'AXS-USD':axs,\n",
    "               'BTC-USD':btc,\n",
    "               'ETH-USD':eth,\n",
    "               'LINK-USD':link,\n",
    "               'LUNA1-USD':luna1,\n",
    "               'MATIC-USD':matic,\n",
    "               'SOL-USD':sol}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23217228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline for a currency\n",
    "curr = btc[btc['Date'] > '2021-01-01']\n",
    "curr = curr['Close']\n",
    "curr_scale = pd.DataFrame(MinMaxScaler().fit_transform(np.array(curr).reshape(-1,1)))\n",
    "\n",
    "#scaled data\n",
    "baseline_ytest_scale = curr_scale[1:]\n",
    "baseline_predictions_scale = curr_scale[:-1]\n",
    "print(\"Scaled Root Mean squared Error - RMSE : \" + str(math.sqrt(mean_squared_error(baseline_ytest_scale, baseline_predictions_scale))))\n",
    "\n",
    "#unscaled data\n",
    "baseline_ytest = curr[1:]\n",
    "baseline_predictions = curr[:-1]\n",
    "\n",
    "print(\"Root Mean squared Error - RMSE : \" + str(math.sqrt(mean_squared_error(baseline_ytest, baseline_predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_coin(curr,df, date, time_step=5):\n",
    "    df = df.copy()\n",
    "    df = ta.add_all_ta_features(df, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=True)\n",
    "    df = df.rename(columns={'Date': 'date','Open':'open','High':'high','Low':'low','Close':'close',\n",
    "                                'Adj Close':'adj_close','Volume':'volume'})\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    \n",
    "    #create dataframe with needed features\n",
    "    closedf = df[['date','close',\"trend_macd\"]]\n",
    "    \n",
    "    closedf = closedf[closedf['date'] > date]\n",
    "    close_stock = closedf.copy()\n",
    "\n",
    "    #set training size\n",
    "    training_size=int(len(closedf)*0.80)\n",
    "    test_size=len(closedf)-training_size\n",
    "    train_data,test_data=closedf.iloc[0:training_size,:],closedf.iloc[training_size:len(closedf),:]\n",
    "    \n",
    "    #normalize price\n",
    "    del train_data['date']\n",
    "    del test_data['date']\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler().fit(np.array(train_data['close']).reshape(-1,1)) \n",
    "    scaler.fit(train_data)\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(train_data)) \n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(test_data))\n",
    "    \n",
    "    #create the looped datasets for \"close\"\n",
    "    X_train, y_train = create_dataset(X_train_scaled, time_step)\n",
    "    X_test, y_test = create_dataset(X_test_scaled, time_step)\n",
    "    \n",
    "    #convert to dataframes\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    #append variables\n",
    "    X_train = pd.concat([X_train, X_train_scaled.iloc[time_step + 1:,1:].reset_index(drop=True)], axis = 1, ignore_index = True)\n",
    "    X_test = pd.concat([X_test, X_test_scaled.iloc[time_step + 1:,1:].reset_index(drop=True)], axis = 1, ignore_index = True)\n",
    "\n",
    "    #convert back to array\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    \n",
    "    #build model\n",
    "    my_model2 = XGBRegressor(n_estimators=1000)\n",
    "    my_model2.fit(X_train, y_train, verbose=True)\n",
    "    \n",
    "    #get predictions\n",
    "    predictions = my_model2.predict(X_test)\n",
    "    scaled_rmse = math.sqrt(mean_squared_error(y_test, predictions))\n",
    "    \n",
    "    train_predict=my_model2.predict(X_train)\n",
    "    test_predict=my_model2.predict(X_test)\n",
    "\n",
    "    train_predict = train_predict.reshape(-1,1)\n",
    "    test_predict = test_predict.reshape(-1,1)\n",
    "\n",
    "    # Transform back to original form\n",
    "    train_predict = scaler_y.inverse_transform(train_predict)\n",
    "    test_predict = scaler_y.inverse_transform(test_predict)\n",
    "    original_ytrain = scaler_y.inverse_transform(y_train.reshape(-1,1)) \n",
    "    original_ytest = scaler_y.inverse_transform(y_test.reshape(-1,1)) \n",
    "    \n",
    "    #get unscaled rmse \n",
    "    RMSE = math.sqrt(mean_squared_error(original_ytest, test_predict))\n",
    "    trainRMSE = math.sqrt(mean_squared_error(original_ytrain, train_predict))\n",
    "    \n",
    "    #Predicting tomorrow\n",
    "    tomorrow_scaled = my_model2.predict(X_test)[-1]\n",
    "    tomorrow = scaler_y.inverse_transform(tomorrow_scaled.reshape(-1,1)) \n",
    "    \n",
    "    #Predicting day after tomorrow\n",
    "    appended_X_test_scaled = X_test_scaled.append([float(tomorrow_scaled)], ignore_index = True)\n",
    "    X_test_append, y_test_append = create_dataset(appended_X_test_scaled, time_step)\n",
    "    \n",
    "    #adding tomorrows variables to dataframe \n",
    "    X_test_append = pd.DataFrame(X_test_append)\n",
    "    X_test_append = pd.concat([X_test_append, X_test_scaled.iloc[time_step + 1:,1:].reset_index(drop=True)], axis = 1, ignore_index = True).fillna(method=\"ffill\")\n",
    "    \n",
    "    #predicting day after tomorrow \n",
    "    tomorrow_tomorrow_scaled = my_model2.predict(X_test_append)[-1]\n",
    "    tomorrow_tomorrow = scaler_y.inverse_transform(tomorrow_tomorrow_scaled.reshape(-1,1)) \n",
    "    \n",
    "    #create output\n",
    "    output = [curr,round(RMSE,4),round(trainRMSE,4), round(float(tomorrow),4), round(float(tomorrow_tomorrow),4) ]\n",
    "    return pd.DataFrame(output).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_output = predict_coin(\"ada\",ada,date='2021-08-01', time_step=15)\n",
    "atom_output = predict_coin(\"atom\",atom,date='2021-01-01')\n",
    "avax_output = predict_coin(\"avax\",avax,date='2021-07-01')\n",
    "axs_output = predict_coin(\"axs\",axs,date='2021-07-01')\n",
    "btc_output = predict_coin(\"btc\",btc,date='2021-05-01', time_step=17)\n",
    "eth_output = predict_coin(\"eth\",eth,date='2021-02-01', time_step=17)\n",
    "link_output = predict_coin(\"link\",link,date='2021-07-01', time_step=17)\n",
    "luna1_output = predict_coin(\"luna1\",luna1,date='2021-05-01')\n",
    "matic_output = predict_coin(\"matic\",matic,date='2021-07-01')\n",
    "sol_output = predict_coin(\"sol\",sol,date='2021-07-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 day default\n",
    "final = pd.concat([ada_output, atom_output, avax_output, axs_output, btc_output, eth_output, link_output,\n",
    "        luna1_output, matic_output, sol_output], axis=0)\n",
    "final.columns = [\"Currency\", \"RMSE Test\",\"RMSE Train\",\"2022-05-09\",\"2022-05-10\"]\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('XGB_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d298e",
   "metadata": {},
   "source": [
    "## LSTM Modeling for all 10 currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "close=pd.read_csv('data/close.csv')\n",
    "adj_close=pd.read_csv('data/adj_close.csv')\n",
    "open=pd.read_csv('data/open.csv')\n",
    "high=pd.read_csv('data/open.csv')\n",
    "low=pd.read_csv('data/low.csv')\n",
    "volume=pd.read_csv('data/volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5100180-25d4-4075-9428-fad109dd1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = close.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corrMatrix, dtype=bool))\n",
    "\n",
    "# Create a custom divergin palette\n",
    "#cmap = sns.diverging_palette(250, 15, s=75, l=40,\n",
    "#                            n=9, center=\"light\", as_cmap=True)\n",
    "cmap = sns.diverging_palette(10, 250, n=256)\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(corrMatrix, mask=mask, center=0, annot=True,\n",
    "            fmt='.2f', square=True, cmap=cmap)\n",
    "plt.savefig('corr.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [close, adj_close, open, high, low, volume]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date'], how='outer'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bcbd1-cd4c-4425-9e07-cb10427aab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare datasets per currency\n",
    "\n",
    "def currency(curr): \n",
    "    df=df_merged[['Date',curr+'_x', curr+'_y']]\n",
    "    df.columns = ['Date','Close', 'Adj_Close','Open','High', 'Low', 'Volume']\n",
    "    df = df.dropna()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    #df = df.loc[df['Date'].dt.year >= 2020]\n",
    "    #df = df.loc[df['Date'].dt.month >= 7]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "ada=currency('ADA-USD')\n",
    "atom=currency('ATOM-USD')\n",
    "avax=currency('AVAX-USD')\n",
    "axs=currency('AXS-USD')\n",
    "btc=currency('BTC-USD')\n",
    "eth=currency('ETH-USD')\n",
    "link=currency('LINK-USD')\n",
    "luna1=currency('LUNA1-USD')\n",
    "matic=currency('MATIC-USD')\n",
    "sol=currency('SOL-USD')\n",
    "\n",
    "#Dictionary with crypto names and datasets\n",
    "crypto_names = {'ADA-USD':ada, \n",
    "               'ATOM-USD':atom,\n",
    "               'AVAX-USD':avax,\n",
    "               'AXS-USD':axs,\n",
    "               'BTC-USD':btc,\n",
    "               'ETH-USD':eth,\n",
    "               'LINK-USD':link,\n",
    "               'LUNA1-USD':luna1,\n",
    "               'MATIC-USD':matic,\n",
    "               'SOL-USD':sol}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF preparing functions for Close and High, also splitting the training/test dataset\n",
    "def lstm_close(curr):\n",
    "    df=curr.reset_index()['Close']\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    df = np.array(df).reshape(-1,1)\n",
    "    #df=scaler.fit_transform(np.array(df).reshape(-1,1))\n",
    "    return scaler,df\n",
    "\n",
    "#Split df using % of choice\n",
    "def split_df(df):\n",
    "    training_size=int(len(df)*0.95)\n",
    "    test_size=len(df)-training_size\n",
    "    train_data,test_data=df[0:training_size,:],df[training_size:len(df),:1]\n",
    "    return train_data,test_data\n",
    "\n",
    "#Using the provided data, create a dataset of sequential values using a timestep (number of days chosen)\n",
    "def create_dataset(dataset, time_step):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        data_x.append(a)\n",
    "        data_y.append(dataset[i + time_step, 0])\n",
    "    return np.array(data_x), np.array(data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b471a4-cf75-4538-9c7e-179dac25f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Macro function to predict the next 2 days for a certain coin.\n",
    "#Returns list with the outputs for the 2 days\n",
    "'''\n",
    "Parameters:\n",
    "name - String with the name of the coin\n",
    "df - dataframe for the coin\n",
    "days - how many days to use as basis for predicting (standard: 15)\n",
    "epochs - how many epochs for the LSTM to run (standard: 20)\n",
    "\n",
    "'''\n",
    "\n",
    "def predict_coin(name,df,days=15,epochs=20):\n",
    "    \n",
    "    scaler,df1 = lstm_close(df)\n",
    "    \n",
    "    #Split dataframe in train test\n",
    "    train_data, test_data = split_df(df1)\n",
    "    \n",
    "    scaler=scaler.fit(train_data)\n",
    "    train_data = scaler.transform(train_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "\n",
    "    \n",
    "    #Set timestep of n days and create datasets to train\n",
    "    time_step = days\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "    \n",
    "    #Reshaping the input as required for LSTM\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        \n",
    "    #Create LSTM model using layers and dropout to avoid overfitting\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(512,activation='relu',return_sequences=True,input_shape=(days,1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256,return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    checkpoint_path = 'checkpoint.keras'\n",
    "    callbacks = [\n",
    "      keras.callbacks.ModelCheckpoint(\n",
    "          filepath=checkpoint_path,\n",
    "          monitor=\"val_loss\",\n",
    "          save_best_only=True,\n",
    "          mode='min'\n",
    "      ),\n",
    "      keras.callbacks.EarlyStopping(\n",
    "          monitor=\"val_loss\",\n",
    "          patience=10,\n",
    "          restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "   \n",
    "    #Fit the model and predict for X_train and X_test. \n",
    "    #After that, present the RMSE for train and test\n",
    "    print(f\"###### PREDICTIONS FOR {name} CRYPTOCURRENCY ######\\n\")\n",
    "    print(f\"Running epochs now, it might take a while\")\n",
    "    model.fit(X_train, y_train, validation_data=(X_test,y_test),epochs=epochs, batch_size=64,verbose=0, callbacks=callbacks)\n",
    "    \n",
    "    model_from_checkpoint = keras.models.load_model(checkpoint_path)\n",
    "    train_predict=model_from_checkpoint.predict(X_train)\n",
    "    test_predict=model_from_checkpoint.predict(X_test)\n",
    "    \n",
    "    #Reshaping and inverse transforming to calculate non scaled RMSE\n",
    "    test_predict=scaler.inverse_transform(test_predict)\n",
    "    train_predict=scaler.inverse_transform(train_predict)\n",
    "    y_test=scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    testdf = pd.DataFrame()\n",
    "    testdf['y_test'] = list(y_test)\n",
    "    testdf['predict'] = list(test_predict)\n",
    "    print(math.sqrt(mean_squared_error(y_test,test_predict)))\n",
    "    rmse = math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "\n",
    "    #Plotting\n",
    "    # Train predictions plot\n",
    "    look_back=days\n",
    "    trainPredictPlot = np.empty_like(df1)\n",
    "    trainPredictPlot[:,:] = np.nan\n",
    "    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "    \n",
    "    # Test predictions plot\n",
    "    testPredictPlot = np.empty_like(df1)\n",
    "    testPredictPlot[:,:] = np.nan\n",
    "    testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "    \n",
    "    #plot original data and predictions with x-axis date information\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['Date'] = df['Date']\n",
    "    temp_df['Train'] = scaler.inverse_transform(trainPredictPlot)\n",
    "    temp_df['Test'] = scaler.inverse_transform(testPredictPlot)\n",
    "    temp_df['Data'] = scaler.inverse_transform(df1)\n",
    "    temp_df.set_index('Date', inplace=True)\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.plot(temp_df['Data'])\n",
    "    plt.plot(temp_df['Train'])\n",
    "    plt.plot(temp_df['Test'])\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(rotation='45')\n",
    "    plt.ylabel(\"Value in USD\")\n",
    "    plt.title(f\"Prediction x Actual for {name}\", fontweight='bold')\n",
    "    plt.legend(['Actual Data', 'TrainPred', 'TestPred'])\n",
    "    plt.show()\n",
    "    \n",
    "    #Reshaping only the last n values for test data\n",
    "    x_input=test_data[len(test_data)-days:].reshape(1,-1)\n",
    "    x_input.shape\n",
    "    \n",
    "    #Prepare list for the loop predictions\n",
    "    temp_input=list(x_input)\n",
    "    temp_input=temp_input[0].tolist()\n",
    "    \n",
    "#Predict the next 2 days (change value of i if want more days)\n",
    "    lst_output=[]\n",
    "    n_steps=days\n",
    "    i=0\n",
    "    while(i<2):\n",
    "        if(len(temp_input)>days):\n",
    "            x_input=np.array(temp_input[1:])\n",
    "            x_input=x_input.reshape(1,-1)\n",
    "            x_input = x_input.reshape((1, n_steps, 1))\n",
    "            predictions=model.predict(x_input, verbose=0)\n",
    "            temp_input.extend(predictions[0].tolist())\n",
    "            temp_input=temp_input[1:]\n",
    "            lst_output.extend(predictions.tolist())\n",
    "            i=i+1\n",
    "        else:\n",
    "            x_input = x_input.reshape((1,n_steps,1))\n",
    "            predictions = model.predict(x_input,verbose=0)\n",
    "            temp_input.extend(predictions[0].tolist())\n",
    "            lst_output.extend(predictions.tolist())\n",
    "            i=i+1\n",
    "    print(f\"\\n###### END OF PREDICTIONS FOR {name} CRYPTO ######\\n\")\n",
    "\n",
    "    lst_output = scaler.inverse_transform(lst_output)\n",
    "    rmse_scores.append(rmse)\n",
    "    return lst_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a8c3c-77ba-4e7b-889b-8ffaef75ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary with names and predictions for all coins. Parameters used: prediction based on last 15 days, 100 epochs.\n",
    "crypto_predictions = {}\n",
    "rmse_scores = []\n",
    "for key,value in crypto_names.items():\n",
    "    crypto_predictions[f'{key}'] = predict_coin(key,value,days=5,epochs=200).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256f8cd-a8d2-43f8-8c38-c4ec88bf7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "day1 = []\n",
    "day2 = []\n",
    "k=0\n",
    "while k<len(list(crypto_predictions.values())):\n",
    "    day1.append((list(crypto_predictions.values())[k][0])[0])\n",
    "    k=k+1\n",
    "k=0    \n",
    "while k<len(list(crypto_predictions.values())):\n",
    "    day2.append((list(crypto_predictions.values())[k][1])[0])\n",
    "    k=k+1\n",
    "\n",
    "data['Index'] = (list(crypto_names.keys()))\n",
    "data['RMSE Score'] = rmse_scores\n",
    "data['Pred - Day1'] = day1\n",
    "data['Pred - Day2'] = day2\n",
    "data.set_index('Index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33eedb2-0822-4a56-8efc-ed41158b7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb90087c-3282-4a58-8c28-33606268456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('lstm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
